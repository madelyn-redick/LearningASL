{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d294fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import random\n",
    "import kagglehub\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24faa5c",
   "metadata": {},
   "source": [
    "word frequency comes from https://www.kaggle.com/datasets/rtatman/english-word-frequency\n",
    "\n",
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dc020df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input and output folders\n",
    "source_root = \"images_folder\"\n",
    "output_root = \"letters\"\n",
    "\n",
    "# define dataset split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# reproducability\n",
    "random.seed(42)\n",
    "\n",
    "# create output subfolders\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "for split in splits:\n",
    "    os.makedirs(os.path.join(output_root, split), exist_ok=True)\n",
    "\n",
    "# loop through each class subfolder\n",
    "for root, dirs, files in os.walk(source_root):\n",
    "    label = os.path.basename(root)\n",
    "\n",
    "    if label == os.path.basename(source_root): # skip folder itself\n",
    "        continue\n",
    "\n",
    "    # get images\n",
    "    image_files = [f for f in files]\n",
    "\n",
    "    # shuffle for random splitting\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # split into train/test/val\n",
    "    n_total = len(image_files)\n",
    "    n_train = int(train_ratio * n_total)\n",
    "    n_val = int(val_ratio * n_total)\n",
    "\n",
    "    split_sets = {\n",
    "        \"train\": image_files[:n_train],\n",
    "        \"val\": image_files[n_train:n_train + n_val],\n",
    "        \"test\": image_files[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    # copy images into structured folders\n",
    "    for split_name, files_in_split in split_sets.items():\n",
    "        split_label_folder = os.path.join(output_root, split_name, label)\n",
    "        os.makedirs(split_label_folder, exist_ok=True)\n",
    "\n",
    "        for idx, file in enumerate(files_in_split, start=1):\n",
    "            image_id = f\"{label.lower()}_{idx}\"\n",
    "            src_path = os.path.join(root, file)\n",
    "            dst_path = os.path.join(split_label_folder, f\"{image_id}.jpg\")\n",
    "            shutil.copy2(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d0e76",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95eef174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - CHOOSE HOW MANY WORDS IN DATASET\n",
    "n = 40  # number of most common words to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73b2ca55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/madelynredick/Documents/code/cs4973_CV/LearningASL/videos_folder'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download dataset to cache\n",
    "download_path = kagglehub.dataset_download(\"waseemnagahhenes/sign-language-dataset-wlasl-videos\")\n",
    "\n",
    "# path to desired folder\n",
    "source_dir = os.path.join(download_path, \"dataset\", \"SL\")\n",
    "\n",
    "# target destination\n",
    "target_dir = os.path.join(os.getcwd(), \"videos_folder\")\n",
    "\n",
    "# move data to working dir\n",
    "shutil.copytree(source_dir, target_dir, dirs_exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f27657ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_dir, video_id):\n",
    "    \"\"\" extracts frames from video and saves to a folder \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    currentframe = 0\n",
    "    while True:\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_name = f\"frame_{currentframe:04d}.jpg\"\n",
    "        cv2.imwrite(os.path.join(output_dir, frame_name), frame)\n",
    "        currentframe += 1\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddfa571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input and output folders\n",
    "source_root = \"videos_folder\"\n",
    "output_root = \"words\"\n",
    "\n",
    "# read and filter word list\n",
    "all_words = [d for d in os.listdir(source_root) if os.path.isdir(os.path.join(source_root, d))]\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "all_words = [w for w in all_words if w not in alphabet]\n",
    "\n",
    "# filter by frequency\n",
    "word_freq = pd.read_csv(\"unigram_freq.csv\")\n",
    "word_freq = word_freq.loc[word_freq[\"word\"].isin(all_words)].reset_index(drop=True)\n",
    "words_train = word_freq[\"word\"].iloc[:n].tolist()\n",
    "\n",
    "# create main output folders\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(output_root, split), exist_ok=True)\n",
    "\n",
    "# traverse through dataset\n",
    "for word in words_train:\n",
    "    word_folder = os.path.join(source_root, word)\n",
    "    if not os.path.exists(word_folder):\n",
    "        continue\n",
    "\n",
    "    # collect all video files for that word\n",
    "    video_files = [os.path.join(word_folder, f) for f in os.listdir(word_folder) if f.lower().endswith((\".mp4\", \".mov\"))]\n",
    "\n",
    "    # shuffle for random splitting\n",
    "    random.shuffle(video_files)\n",
    "\n",
    "    # split into train/test/val\n",
    "    n_total = len(video_files)\n",
    "    n_train = int(train_ratio * n_total)\n",
    "    n_val = int(val_ratio * n_total)\n",
    "\n",
    "    split_sets = {\n",
    "        \"train\": video_files[:n_train],\n",
    "        \"val\": video_files[n_train:n_train + n_val],\n",
    "        \"test\": video_files[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    # process and extract frames\n",
    "    for split_name, split_videos in split_sets.items():\n",
    "        for idx, video_path in enumerate(split_videos, start=1):\n",
    "            video_id = f\"{word}_{idx}\"\n",
    "            output_dir = os.path.join(output_root, split_name, word, video_id)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            extract_frames(video_path, output_dir, video_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0badf",
   "metadata": {},
   "source": [
    "# Test Data Loader in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a41370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# letters / images\n",
    "letter_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "letter_train = datasets.ImageFolder(root='letters/train', transform=letter_transform)\n",
    "letter_val = datasets.ImageFolder(root='letters/val', transform=letter_transform)\n",
    "letter_test = datasets.ImageFolder(root='letters/test', transform=letter_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0124439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words / videos\n",
    "class VideoFrameDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        for class_name in os.listdir(root):\n",
    "            class_path = os.path.join(root, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "            for video_folder in os.listdir(class_path):\n",
    "                video_path = os.path.join(class_path, video_folder)\n",
    "                frames = sorted(glob.glob(os.path.join(video_path, \"*.jpg\")))\n",
    "                for frame in frames:\n",
    "                    self.samples.append((frame, class_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "word_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "word_train = VideoFrameDataset(root='words/train', transform=word_transform)\n",
    "word_val = VideoFrameDataset(root='words/val', transform=word_transform)\n",
    "word_test  = VideoFrameDataset(root='words/test', transform=word_transform)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
