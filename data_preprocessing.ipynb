{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d294fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24faa5c",
   "metadata": {},
   "source": [
    "word frequency comes from https://www.kaggle.com/datasets/rtatman/english-word-frequency\n",
    "\n",
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2dc020df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input and output folders\n",
    "source_root = \"images_folder\"\n",
    "output_root = \"letters\"\n",
    "\n",
    "# define dataset split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# reproducability\n",
    "random.seed(42)\n",
    "\n",
    "# create output subfolders\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "for split in splits:\n",
    "    os.makedirs(os.path.join(output_root, split), exist_ok=True)\n",
    "\n",
    "# loop through each class subfolder\n",
    "for root, dirs, files in os.walk(source_root):\n",
    "    label = os.path.basename(root)\n",
    "\n",
    "    if label == os.path.basename(source_root): # skip folder itself\n",
    "        continue\n",
    "\n",
    "    # get images\n",
    "    image_files = [f for f in files]\n",
    "\n",
    "    # shuffle for random splitting\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # split into train/test/val\n",
    "    n_total = len(image_files)\n",
    "    n_train = int(train_ratio * n_total)\n",
    "    n_val = int(val_ratio * n_total)\n",
    "\n",
    "    split_sets = {\n",
    "        \"train\": image_files[:n_train],\n",
    "        \"val\": image_files[n_train:n_train + n_val],\n",
    "        \"test\": image_files[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    # copy images into structured folders\n",
    "    for split_name, files_in_split in split_sets.items():\n",
    "        split_label_folder = os.path.join(output_root, split_name, label)\n",
    "        os.makedirs(split_label_folder, exist_ok=True)\n",
    "\n",
    "        for idx, file in enumerate(files_in_split, start=1):\n",
    "            image_id = f\"{label.lower()}_{idx}\"\n",
    "            src_path = os.path.join(root, file)\n",
    "            dst_path = os.path.join(split_label_folder, f\"{image_id}.jpg\")\n",
    "            shutil.copy2(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d0e76",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95eef174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - CHOOSE HOW MANY WORDS IN DATASET\n",
    "n = 40  # number of most common words to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f27657ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_dir, video_id):\n",
    "    \"\"\" extracts frames from video and saves to a folder \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    currentframe = 0\n",
    "    while True:\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_name = f\"frame_{currentframe:04d}.jpg\"\n",
    "        cv2.imwrite(os.path.join(output_dir, frame_name), frame)\n",
    "        currentframe += 1\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddfa571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input and output folders\n",
    "source_root = \"videos_folder\"\n",
    "output_root = \"words\"\n",
    "\n",
    "# read and filter word list\n",
    "all_words = [d for d in os.listdir(source_root) if os.path.isdir(os.path.join(source_root, d))]\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "all_words = [w for w in all_words if w not in alphabet]\n",
    "\n",
    "# filter by frequency\n",
    "word_freq = pd.read_csv(\"unigram_freq.csv\")\n",
    "word_freq = word_freq.loc[word_freq[\"word\"].isin(all_words)].reset_index(drop=True)\n",
    "words_train = word_freq[\"word\"].iloc[:n].tolist()\n",
    "\n",
    "# create main output folders\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(output_root, split), exist_ok=True)\n",
    "\n",
    "# traverse through dataset\n",
    "for word in words_train:\n",
    "    word_folder = os.path.join(source_root, word)\n",
    "    if not os.path.exists(word_folder):\n",
    "        continue\n",
    "\n",
    "    # collect all video files for that word\n",
    "    video_files = [os.path.join(word_folder, f) for f in os.listdir(word_folder)]\n",
    "\n",
    "    # shuffle for random splitting\n",
    "    random.shuffle(video_files)\n",
    "\n",
    "    # split into train/test/val\n",
    "    n_total = len(video_files)\n",
    "    n_train = int(train_ratio * n_total)\n",
    "    n_val = int(val_ratio * n_total)\n",
    "\n",
    "    split_sets = {\n",
    "        \"train\": video_files[:n_train],\n",
    "        \"val\": video_files[n_train:n_train + n_val],\n",
    "        \"test\": video_files[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    # process and extract frames\n",
    "    for split_name, split_videos in split_sets.items():\n",
    "        for idx, video_path in enumerate(split_videos, start=1):\n",
    "            video_id = f\"{word}_{idx}\"\n",
    "            output_dir = os.path.join(output_root, split_name, word, video_id)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            extract_frames(video_path, output_dir, video_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0badf",
   "metadata": {},
   "source": [
    "# Test Data Loader in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a41370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# letters / images\n",
    "letter_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "letter_train= datasets.ImageFolder(root='letters/train', transform=letter_transform)\n",
    "letter_val   = datasets.ImageFolder(root='letters/val', transform=letter_transform)\n",
    "letter_test  = datasets.ImageFolder(root='letters/test', transform=letter_transform)\n",
    "\n",
    "\n",
    "# words / videos\n",
    "word_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "word_train= datasets.ImageFolder(root='words/train', transform=word_transform)\n",
    "word_val   = datasets.ImageFolder(root='words/val', transform=word_transform)\n",
    "word_test  = datasets.ImageFolder(root='words/test', transform=word_transform)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
